{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVYtns20U5M2"
      },
      "source": [
        "**Experimento con LeNet sobre MNIST (Optimización)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYK0zeE_U5M3"
      },
      "source": [
        "**Lectura del corpus mnist, partición train y test y normalización**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCqPB0iEKzYt",
        "outputId": "e75568a5-28fc-425a-8fb4-d34e2115c5ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "training set (60000, 28, 28)\n",
            "test set (10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print('training set', x_train.shape)\n",
        "print('test set', x_test.shape)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalize [0..255]-->[0..1]\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "num_classes=10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96tNlNaDU5M5"
      },
      "source": [
        "\n",
        "**Optimización con conjunto de validación**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O03C3oUdU5M6"
      },
      "source": [
        "Hacemos la partición entrenamiento/validación (80%/20%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSb14JQXU5M6",
        "outputId": "2dbc6c35-2b1b-469e-86a0-c2e58d6796d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training set (48000, 28, 28)\n",
            "val set (12000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print('training set', x_train.shape)\n",
        "print('val set', x_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of85VJG1U5M8"
      },
      "source": [
        "**Optimización del modelo en función del learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGhsa4LKU5M8",
        "outputId": "5665cc33-4778-4735-b2b4-5629aa3bc86a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate: 0.0001\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 2.3314 - accuracy: 0.0417 - val_loss: 2.3214 - val_accuracy: 0.0485\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.3143 - accuracy: 0.0566 - val_loss: 2.3049 - val_accuracy: 0.0650\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2978 - accuracy: 0.0745 - val_loss: 2.2889 - val_accuracy: 0.0857\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2818 - accuracy: 0.0936 - val_loss: 2.2733 - val_accuracy: 0.1058\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.2661 - accuracy: 0.1129 - val_loss: 2.2579 - val_accuracy: 0.1249\n",
            "Learning rate: 0.001\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 2.2412 - accuracy: 0.2404 - val_loss: 2.1445 - val_accuracy: 0.3691\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 2.0306 - accuracy: 0.5140 - val_loss: 1.9024 - val_accuracy: 0.6062\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7468 - accuracy: 0.6433 - val_loss: 1.5887 - val_accuracy: 0.6683\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.4396 - accuracy: 0.6863 - val_loss: 1.3036 - val_accuracy: 0.7023\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.1944 - accuracy: 0.7196 - val_loss: 1.0973 - val_accuracy: 0.7379\n",
            "Learning rate: 0.01\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 1.4556 - accuracy: 0.6350 - val_loss: 0.7201 - val_accuracy: 0.8321\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5625 - accuracy: 0.8596 - val_loss: 0.4661 - val_accuracy: 0.8792\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.4246 - accuracy: 0.8859 - val_loss: 0.3870 - val_accuracy: 0.8920\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3677 - accuracy: 0.8979 - val_loss: 0.3440 - val_accuracy: 0.9030\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3325 - accuracy: 0.9056 - val_loss: 0.3143 - val_accuracy: 0.9102\n",
            "Learning rate: 0.1\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 0.4491 - accuracy: 0.8766 - val_loss: 0.2165 - val_accuracy: 0.9373\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1765 - accuracy: 0.9484 - val_loss: 0.1375 - val_accuracy: 0.9601\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1175 - accuracy: 0.9653 - val_loss: 0.1077 - val_accuracy: 0.9698\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0915 - accuracy: 0.9727 - val_loss: 0.0841 - val_accuracy: 0.9743\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0752 - accuracy: 0.9778 - val_loss: 0.0734 - val_accuracy: 0.9788\n",
            "Best acc 0.9788333177566528\n",
            "Best learning rate 0.1\n"
          ]
        }
      ],
      "source": [
        "from keras.optimizers import SGD\n",
        "\n",
        "batch_size=128\n",
        "epochs=5\n",
        "\n",
        "LR=[0.0001,0.001,0.01,0.1]\n",
        "best_acc=0.0\n",
        "for lr in LR:\n",
        "  M = keras.Sequential()\n",
        "  M.add(keras.layers.Conv2D(filters=6, kernel_size=(5,5), activation='tanh', input_shape=(28,28,1)))\n",
        "  M.add(keras.layers.AveragePooling2D(pool_size=(2,2), strides=2))\n",
        "  M.add(keras.layers.Conv2D(filters=16, kernel_size=(5,5), activation='tanh'))\n",
        "  M.add(keras.layers.AveragePooling2D(pool_size=(2,2), strides=2))\n",
        "  M.add(keras.layers.Flatten())\n",
        "  M.add(keras.layers.Dense(units=120, activation='tanh'))\n",
        "  M.add(keras.layers.Dense(units=84, activation='tanh'))\n",
        "  M.add(keras.layers.Dense(units=10, activation = 'softmax'))\n",
        "  sgd=SGD(learning_rate=lr)\n",
        "  M.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "  print(\"Learning rate:\",lr)\n",
        "  H = M.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val, y_val))\n",
        "\n",
        "  if H.history['val_accuracy'][-1]>best_acc:\n",
        "        best_acc=H.history['val_accuracy'][-1]\n",
        "        bestlr=lr\n",
        "\n",
        "print(\"Best acc\",best_acc)\n",
        "print(\"Best learning rate\",bestlr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CulV6x7tgCnL"
      },
      "source": [
        "\n",
        "EARLY STOPPING\n",
        "\n",
        "El número de épocas a emplear se puede ajustar en función de cómo evoluciona la convergencia sobre el conjunto de validación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdMFwUj8gabk",
        "outputId": "71fa50fa-7377-46e0-9367-f02f1b39539c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate: 0.1\n",
            "Epoch 1/100\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 0.4624 - accuracy: 0.8715 - val_loss: 0.2350 - val_accuracy: 0.9306\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1950 - accuracy: 0.9423 - val_loss: 0.1546 - val_accuracy: 0.9540\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1355 - accuracy: 0.9597 - val_loss: 0.1152 - val_accuracy: 0.9655\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1050 - accuracy: 0.9682 - val_loss: 0.0967 - val_accuracy: 0.9710\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0849 - accuracy: 0.9753 - val_loss: 0.0794 - val_accuracy: 0.9761\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0731 - accuracy: 0.9784 - val_loss: 0.0815 - val_accuracy: 0.9740\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0636 - accuracy: 0.9804 - val_loss: 0.0673 - val_accuracy: 0.9787\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0567 - accuracy: 0.9832 - val_loss: 0.0668 - val_accuracy: 0.9802\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0509 - accuracy: 0.9846 - val_loss: 0.0584 - val_accuracy: 0.9815\n",
            "Best acc 0.9815000295639038\n",
            "Best learning rate 0.1\n"
          ]
        }
      ],
      "source": [
        "from keras.optimizers import SGD\n",
        "\n",
        "batch_size=128\n",
        "epochs=100\n",
        "\n",
        "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=2)\n",
        "\n",
        "LR=[0.1]\n",
        "best_acc=0.0\n",
        "for lr in LR:\n",
        "  M = keras.Sequential()\n",
        "  M.add(keras.layers.Conv2D(filters=6, kernel_size=(5,5), activation='tanh', input_shape=(28,28,1)))\n",
        "  M.add(keras.layers.AveragePooling2D(pool_size=(2,2), strides=2))\n",
        "  M.add(keras.layers.Conv2D(filters=16, kernel_size=(5,5), activation='tanh'))\n",
        "  M.add(keras.layers.AveragePooling2D(pool_size=(2,2), strides=2))\n",
        "  M.add(keras.layers.Flatten())\n",
        "  M.add(keras.layers.Dense(units=120, activation='tanh'))\n",
        "  M.add(keras.layers.Dense(units=84, activation='tanh'))\n",
        "  M.add(keras.layers.Dense(units=10, activation = 'softmax'))\n",
        "  sgd=SGD(learning_rate=lr)\n",
        "  M.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "  print(\"Learning rate:\",lr)\n",
        "  H = M.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val, y_val),callbacks=[callback])\n",
        "\n",
        "  if H.history['val_accuracy'][-1]>best_acc:\n",
        "        best_acc=H.history['val_accuracy'][-1]\n",
        "        bestlr=lr\n",
        "\n",
        "print(\"Best acc\",best_acc)\n",
        "print(\"Best learning rate\",bestlr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOwcWActgCkp"
      },
      "source": [
        "**Optimización del modelo en función de diferentes optimizadores**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzAznWPSinWK",
        "outputId": "cbfcef9b-0d39-446a-abbd-3c3ebd59a975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizador: <keras.src.optimizers.sgd.SGD object at 0x7863100ef190>\n",
            "Epoch 1/100\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 0.4665 - accuracy: 0.8683 - val_loss: 0.2315 - val_accuracy: 0.9322\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1876 - accuracy: 0.9443 - val_loss: 0.1449 - val_accuracy: 0.9576\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1279 - accuracy: 0.9618 - val_loss: 0.1094 - val_accuracy: 0.9684\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0990 - accuracy: 0.9708 - val_loss: 0.0895 - val_accuracy: 0.9740\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0816 - accuracy: 0.9760 - val_loss: 0.0773 - val_accuracy: 0.9774\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0703 - accuracy: 0.9796 - val_loss: 0.0695 - val_accuracy: 0.9794\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0615 - accuracy: 0.9818 - val_loss: 0.0629 - val_accuracy: 0.9816\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0553 - accuracy: 0.9840 - val_loss: 0.0584 - val_accuracy: 0.9837\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0503 - accuracy: 0.9854 - val_loss: 0.0563 - val_accuracy: 0.9841\n",
            "Optimizador: <keras.src.optimizers.adam.Adam object at 0x7863100ef1f0>\n",
            "Epoch 1/100\n",
            "375/375 [==============================] - 4s 6ms/step - loss: 2.4273 - accuracy: 0.2119 - val_loss: 1.9259 - val_accuracy: 0.3223\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.5895 - accuracy: 0.4616 - val_loss: 1.3789 - val_accuracy: 0.5150\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.2636 - accuracy: 0.5809 - val_loss: 1.0081 - val_accuracy: 0.6502\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5685 - accuracy: 0.5091 - val_loss: 2.0971 - val_accuracy: 0.2657\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.9075 - accuracy: 0.3217 - val_loss: 1.7752 - val_accuracy: 0.3907\n",
            "Optimizador: <keras.src.optimizers.adagrad.Adagrad object at 0x7863100efaf0>\n",
            "Epoch 1/100\n",
            "375/375 [==============================] - 4s 5ms/step - loss: 0.2956 - accuracy: 0.9110 - val_loss: 0.1336 - val_accuracy: 0.9583\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1066 - accuracy: 0.9674 - val_loss: 0.0798 - val_accuracy: 0.9758\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0716 - accuracy: 0.9782 - val_loss: 0.0741 - val_accuracy: 0.9769\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0544 - accuracy: 0.9833 - val_loss: 0.0550 - val_accuracy: 0.9836\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0446 - accuracy: 0.9865 - val_loss: 0.0513 - val_accuracy: 0.9843\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0373 - accuracy: 0.9888 - val_loss: 0.0477 - val_accuracy: 0.9858\n",
            "=============================\n",
            "Best acc 0.9858333468437195\n",
            "Best optim <keras.src.optimizers.adagrad.Adagrad object at 0x7863100efaf0>\n",
            "=============================\n"
          ]
        }
      ],
      "source": [
        "from keras.optimizers import SGD,Adam,Adagrad\n",
        "\n",
        "batch_size=128\n",
        "epochs=100\n",
        "lr=0.1\n",
        "\n",
        "opt=[]\n",
        "opt.append(SGD(learning_rate=lr))\n",
        "opt.append(Adam(learning_rate=lr))\n",
        "opt.append(Adagrad(learning_rate=lr))\n",
        "\n",
        "best_acc=0.0\n",
        "for optim in opt:\n",
        "    print(\"Optimizador:\",optim)\n",
        "    M = keras.Sequential()\n",
        "    M.add(keras.layers.Conv2D(filters=6, kernel_size=(5,5), activation='tanh', input_shape=(28,28,1)))\n",
        "    M.add(keras.layers.AveragePooling2D(pool_size=(2,2), strides=2))\n",
        "    M.add(keras.layers.Conv2D(filters=16, kernel_size=(5,5), activation='tanh'))\n",
        "    M.add(keras.layers.AveragePooling2D(pool_size=(2,2), strides=2))\n",
        "    M.add(keras.layers.Flatten())\n",
        "    M.add(keras.layers.Dense(units=120, activation='tanh'))\n",
        "    M.add(keras.layers.Dense(units=84, activation='tanh'))\n",
        "    M.add(keras.layers.Dense(units=10, activation = 'softmax'))\n",
        "    M.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optim,\n",
        "              metrics=['accuracy'])\n",
        "    H = M.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val, y_val),callbacks=[callback])\n",
        "\n",
        "    if H.history['val_accuracy'][-1]>best_acc:\n",
        "        best_acc=H.history['val_accuracy'][-1]\n",
        "        bestopt=optim\n",
        "\n",
        "print(\"=============================\")\n",
        "print(\"Best acc\",best_acc)\n",
        "print(\"Best optim\",bestopt)\n",
        "print(\"=============================\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
