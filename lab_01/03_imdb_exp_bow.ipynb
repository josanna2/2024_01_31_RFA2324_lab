{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Montamos la unidad Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Leemos el IMDB Dataset of 50K Movie Reviews**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VmSFUPYDR2bS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd , numpy as np\n",
        "\n",
        "#imdb = pd.read_csv('IMDB_prepro.csv')\n",
        "imdb = pd.read_csv('/content/drive/MyDrive/IMDB_prepro.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1CPyye9R2bV"
      },
      "source": [
        "**Dividimos las muestras en dos particiones: 80% train / 20 % test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CU2y8Et2R2bW"
      },
      "outputs": [],
      "source": [
        "imdb_train=imdb.review[:40000]\n",
        "imdb_test=imdb.review[40000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glCSiWWLR2bY"
      },
      "source": [
        "**Transformamos las etiquetas de clase a valores numéricos y hacemos la misma partición train/test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "q4dR3Z6MR2bZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "#labeling the sentient data\n",
        "lb=LabelBinarizer()\n",
        "#transformed sentiment data\n",
        "sentiment_data=lb.fit_transform(imdb['sentiment'])\n",
        "#Spliting the sentiment data\n",
        "train_labels=sentiment_data[:40000]\n",
        "test_labels=sentiment_data[40000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGUktC1pR2bb"
      },
      "source": [
        "**Representamos las muestras utilizando el modelo bag of words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cgRxAzy0R2bb"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#Count vectorizer for bag of words\n",
        "#cv=CountVectorizer(min_df=0,max_df=1,binary=False,max_features=None,ngram_range=(1, 3))\n",
        "cv=CountVectorizer(min_df=0,max_df=1000000,binary=False,max_features=None,ngram_range=(1, 3))\n",
        "#cv=CountVectorizer(min_df=0,max_df=1000000,binary=False,max_features=20,ngram_range=(1, 1))\n",
        "#transformed train reviews\n",
        "cv_imdb_train=cv.fit_transform(imdb_train)\n",
        "#transformed test reviews\n",
        "cv_imdb_test=cv.transform(imdb_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-SI4IKzR2bd"
      },
      "source": [
        "**Entrenamos un clasificador Naive Bayes multinomial**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_nmQcQ60R2be"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "imdb_mnb=MultinomialNB()\n",
        "imdb_mnb_bow=imdb_mnb.fit(cv_imdb_train,train_labels.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_vjb5qAR2bf"
      },
      "source": [
        "**Evaluamos el modelo sobre el test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfnjGe7ObwlJ"
      },
      "source": [
        "**1. Matriz de confusión**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfEdh6SzbzPP",
        "outputId": "10a6d3ad-7de9-46a6-99c4-5ed2cf66211c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "imdb_mnb_bow_predict=imdb_mnb_bow.predict(cv_imdb_test)\n",
        "imdb_cm_bow=confusion_matrix(test_labels,imdb_mnb_bow_predict,labels=[1,0])\n",
        "print(imdb_cm_bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRqXUiErbb7r"
      },
      "source": [
        "**2. Error de clasificación**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vf6hqjyR2bh",
        "outputId": "5408da64-fd83-4164-fad8-f655028bd52e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "imdb_mnb_bow_score=accuracy_score(test_labels,imdb_mnb_bow_predict)\n",
        "print(\"mnb_bow_score :\",imdb_mnb_bow_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Curva ROC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "imdb_mnb_bow_probs = imdb_mnb_bow.predict_proba(cv_imdb_test)[:,1];\n",
        "fpr, tpr, _ = metrics.roc_curve(test_labels,imdb_mnb_bow_probs,pos_label=1);\n",
        "\n",
        "plt.plot(fpr,tpr)\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. Area Under the ROC Curve (AUC)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "auc = metrics.roc_auc_score(test_labels,imdb_mnb_bow_probs);\n",
        "print(\"Dev AUC: %.2f%%\" % (auc*100));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**5. Medidas Precision, Recall y f1-score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "imdb_mnb_bow_report=classification_report(test_labels,imdb_mnb_bow_predict,target_names=['Positive','Negative'])\n",
        "print(imdb_mnb_bow_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**6. Curva Precision-Recall**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
        "\n",
        "fpr, tpr, _ = metrics.precision_recall_curve(test_labels,imdb_mnb_bow_probs,pos_label=1);\n",
        "\n",
        "plt.plot(fpr,tpr)\n",
        "plt.ylabel('Precision')\n",
        "plt.xlabel('Recall')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
